#!/usr/bin/env python3
"""
Parse execution_*.txt files and compute metrics:
- Throughput = terminated_count / total_time
- Avg Wait Time = average time spent in READY state per process
- Avg Turnaround = average completion_time - arrival_time
- Avg Response (arrival->first run)
- Avg I/O Duration = average WAITING duration (io completion)

Output CSV: results_summary.csv and a basic report report.md
"""
import os
import re
import glob
import statistics
from collections import defaultdict

ROOT = os.path.join(os.path.dirname(__file__), '..')

def parse_exec_file(path):
    # Returns per-pid transitions: pid -> list of (time, old, new)
    transitions = defaultdict(list)
    time_re = re.compile(r"\|\s*(\d+)\s*\|\s*(\d+)\s*\|\s*([A-Z_]+)\s*\|\s*([A-Z_]+)\s*\|")
    last_time = 0
    with open(path, 'r') as f:
        for line in f:
            m = time_re.search(line)
            if not m:
                continue
            t = int(m.group(1))
            pid = int(m.group(2))
            old = m.group(3).strip()
            new = m.group(4).strip()
            transitions[pid].append((t, old, new))
            if t > last_time: last_time = t
    return transitions, last_time

def compute_metrics_from_transitions(transitions, sim_end_time):
    per_proc = {}
    terminated = 0

    io_durations = []
    resp_times = []

    for pid, events in transitions.items():
        # events are in chronological order already
        arrival_time = None
        completion_time = None
        first_run_time = None
        waiting_time = 0
        last_state = None
        last_time = None

        # To compute I/O durations, track waiting intervals
        for idx, (t, old, new) in enumerate(events):
            # Determine arrival
            if old == 'NEW' and new == 'READY' and arrival_time is None:
                arrival_time = t

            if new == 'RUNNING' and first_run_time is None:
                first_run_time = t

            if new == 'TERMINATED':
                completion_time = t

            # Track state durations by looking at new state and next event time
            # We'll rely on the next transition time for this pid to compute how long it stayed in the new state
        # Now compute durations using pairs
        for i, (t, old, new) in enumerate(events):
            t_start = t
            # end time is next event for this pid if exists, otherwise sim_end_time
            if i+1 < len(events):
                t_end = events[i+1][0]
            else:
                t_end = sim_end_time

            # The process was in state 'new' during [t_start, t_end)
            if new == 'READY':
                waiting_time += (t_end - t_start)
            if new == 'WAITING':
                # io started at t_start, ended when it becomes READY next for this pid
                # Find the subsequent READY event in later transitions
                for j in range(i+1, len(events)):
                    if events[j][2] == 'READY':
                        io_durations.append(events[j][0] - t_start)
                        break

        if completion_time is not None:
            terminated += 1

        if arrival_time is None and events:
            # fallback: use first event time
            arrival_time = events[0][0]

        if arrival_time is not None and first_run_time is not None:
            resp_times.append(first_run_time - arrival_time)

        turnaround = None
        if arrival_time is not None and completion_time is not None:
            turnaround = completion_time - arrival_time

        per_proc[pid] = {
            'arrival': arrival_time,
            'completion': completion_time,
            'first_run': first_run_time,
            'waiting_time': waiting_time,
            'turnaround': turnaround
        }

    # aggregate metrics
    processes = list(per_proc.values())
    n = len(processes)
    avg_wait = statistics.mean([p['waiting_time'] for p in processes]) if n>0 else 0
    avg_turn = statistics.mean([p['turnaround'] for p in processes if p['turnaround'] is not None]) if n>0 else 0
    avg_resp = statistics.mean(resp_times) if resp_times else 0
    avg_io = statistics.mean(io_durations) if io_durations else 0
    throughput = terminated / sim_end_time if sim_end_time>0 else 0

    return {
        'num_processes': n,
        'terminated': terminated,
        'sim_end_time': sim_end_time,
        'throughput': throughput,
        'avg_wait': avg_wait,
        'avg_turn': avg_turn,
        'avg_resp_arrival': avg_resp,
        'avg_io_duration': avg_io
    }

def main():
    root = ROOT
    # capture both execution_*.txt (original) and executiongen_*.txt (generated by current student code)
    pattern = os.path.join(root, 'execution*.txt')
    files = sorted(glob.glob(pattern))
    rows = []
    for f in files:
        transitions, last_time = parse_exec_file(f)
        metrics = compute_metrics_from_transitions(transitions, last_time)
        base = os.path.basename(f)
        # try to infer scheduler from filename if present; otherwise mark as unknown
        # filenames are like execution_testgen_1_cpu.txt or execution1.txt
        label = base.replace('execution_', '').replace('.txt','')
        print(f"Parsed {f}: {metrics}")
        row = (label, f, metrics)
        rows.append(row)

    # write CSV summary
    outcsv = os.path.join(root, 'results_summary.csv')
    with open(outcsv, 'w') as out:
        out.write('label,filename,num_processes,terminated,sim_end_time,throughput,avg_wait,avg_turn,avg_resp_arrival,avg_io_duration\n')
        for label, fname, m in rows:
            out.write(f"{label},{os.path.basename(fname)},{m['num_processes']},{m['terminated']},{m['sim_end_time']},{m['throughput']:.6f},{m['avg_wait']:.6f},{m['avg_turn']:.6f},{m['avg_resp_arrival']:.6f},{m['avg_io_duration']:.6f}\n")

    # Basic report (markdown)
    rpt = os.path.join(root, 'report.md')
    with open(rpt, 'w') as r:
        r.write('# Simulation Results Summary\n\n')
        r.write('This file contains an aggregated CSV of computed metrics for each execution_*.txt file.\n\n')
        r.write('See `results_summary.csv` for the numeric results.\n\n')
        r.write('Notes on metrics computed:\n')
        r.write('- Throughput = terminated processes / simulation end time (ms)\n')
        r.write('- Avg Wait Time = average time spent in READY state per process (ms)\n')
        r.write('- Avg Turnaround = average (completion_time - arrival_time) (ms)\n')
        r.write('- Avg Response (arrival->first RUNNING) = average initial latency (ms)\n')
        r.write('- Avg I/O Duration = average WAITING period between WAITING and READY transitions (ms)\n\n')
        r.write('Generated files parsed:\n')
        for label, fname, m in rows:
            r.write(f"- {label}: throughput={m['throughput']:.4f}, avg_wait={m['avg_wait']:.2f}, avg_turn={m['avg_turn']:.2f}, avg_resp={m['avg_resp_arrival']:.2f}, avg_io={m['avg_io_duration']:.2f}\n")

    print(f"Wrote CSV {outcsv} and report {rpt}")

if __name__ == '__main__':
    main()
